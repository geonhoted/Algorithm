{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "867d58fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import openpyxl "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a5333a",
   "metadata": {},
   "source": [
    "### 엑셀 파일 생성하기\n",
    "파일명, 시트명, 컬럼명을 정해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6f049e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#엑셀파일 생성\n",
    "wb = openpyxl.Workbook(\"크롤링_상품_추가1.xlsx\")        \n",
    "ws = wb.create_sheet(\"시트명\")             \n",
    "ws.append(['브랜드','상품명','카테고리','정가','할인가','아이디','별점','피부정보','피부타입','피부고민','자극도'])  #컬럼명 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c761efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################제공하는 코드 건드리지 마세요 #############################\n",
    " \n",
    "#크롬 드라이버 자동 업데이트\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# 브라우저 꺼짐 방지\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_experimental_option('detach', True)\n",
    "\n",
    "# 불필요한 에러 메세지 없애기\n",
    "chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "\n",
    "# 크롬 드라이버 경로 지정\n",
    "driver_path = r\"C:/Windows/chromedriver.exe\"  # 여기에 자신이 설치한 크롬 드라이버의 경로를 입력\n",
    "chromedriver_version = \"114.0.5735.16\"\n",
    "\n",
    "# 크롬 드라이버 생성\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager(driver_version=chromedriver_version).install()),options=chrome_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2202a3e1",
   "metadata": {},
   "source": [
    "### 올리브영 스킨케어 랭킹 링크를 main_url로 두고 5위까지 제품 상세 링크를 sub_url에 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f62a7b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = 'https://www.oliveyoung.co.kr/store/main/getBestList.do?dispCatNo=900000100100001&fltDispCatNo=10000010001&pageIdx=1&rowsPerPage=8'\n",
    "\n",
    "response = requests.get(main_url)\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "links = soup.select(\"ul.cate_prd_list > li > div.prd_info > a\") #빈칸채우기\n",
    "\n",
    "\n",
    "# for반복문을 활용하여 5위까지 제품별 상세링크 sub_url에 저장\n",
    "rank = ['1위', '2위', '3위', '4위', '5위']\n",
    "\n",
    "sub_url = []\n",
    "\n",
    "for link in links:\n",
    "    sub_url.append(link['href'])\n",
    "    \n",
    "# 5개의 링크 추출\n",
    "sub_url = sub_url[:20]\n",
    "\n",
    "# 순위와 링크가 담긴 데이터프레임 생성\n",
    "#import pandas as pd\n",
    "\n",
    "#data = {'순위':rank, '상세링크':sub_url}\n",
    "\n",
    "#df = pd.DataFrame(data)\n",
    "\n",
    "#print(df)\n",
    "\n",
    "#time.sleep(1)\n",
    "\n",
    "# 1위 인덱스 0,  2위 인덱스1, 3위 인덱스2, 4위 인덱스3, 5위 인덱스4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905dc1dd",
   "metadata": {},
   "source": [
    "### 크롤링 함수 만들기\n",
    "제품 상세 페이지에서 상단 제품정보(브랜드명,상품명,카테고리,정가,할인가)와  \n",
    "하단의 리뷰고객 좌픅정보(아이디,별점,피부정보)와 우측정보(피부타입,피부고민,자극도)를 가져옵니다.  \n",
    "위의 데이터를 엑셀에 계속 추가하는 함수를 만듭니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b154cbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customer_info():\n",
    "\n",
    "    for j in range(0, 10, 1):\n",
    "        \n",
    "        #브랜드\n",
    "        try:\n",
    "            brand = driver.find_element(By.CSS_SELECTOR, \"p.prd_brand > a\").text\n",
    "        except:\n",
    "            brand =\"없음\"\n",
    "\n",
    "        #상품명\n",
    "        try:\n",
    "            p_name = driver.find_element(By.CSS_SELECTOR, \"p.prd_name\").text\n",
    "        except:\n",
    "            p_name=\"없음\"\n",
    "\n",
    "        #카테고리\n",
    "        try:\n",
    "            p_category = driver.find_element(By.ID, \"dtlCatNm\").text\n",
    "        except:\n",
    "            p_category=\"없음\"\n",
    "\n",
    "        #정가\n",
    "        try:\n",
    "            price = driver.find_element(By.CSS_SELECTOR, 'span.price-1 > strike').text\n",
    "        except:\n",
    "            price=0\n",
    "\n",
    "        #할인가\n",
    "        try:\n",
    "            discount = driver.find_element(By.CSS_SELECTOR, 'span.price-2 > strong').text\n",
    "        except:\n",
    "            discount=0\n",
    "\n",
    "        #고객 아이디\n",
    "        try:\n",
    "            _id = driver.find_element(By.CSS_SELECTOR, f'#gdasList > li:nth-child({j+1}) > div.info > div > p.info_user > a.id').text\n",
    "        except:\n",
    "            _id =\"없음\"\n",
    "\n",
    "        #별점\n",
    "        try:\n",
    "            _star = driver.find_element(By.CSS_SELECTOR, f'#gdasList > li:nth-child({j+1}) > div.review_cont > div.score_area > span.review_point > span').text\n",
    "        except:\n",
    "            _star=\"없음\"\n",
    "\n",
    "        #고객 피부 정보\n",
    "        try:\n",
    "            _info = driver.find_element(By.CSS_SELECTOR, f'#gdasList > li:nth-child({j+1}) > div.info > div > p.tag').text\n",
    "        except:\n",
    "            _info = \"없음\"\n",
    "\n",
    "        #피부 타입\n",
    "        try:\n",
    "            skin_type = driver.find_element(By.CSS_SELECTOR, f'#gdasList > li:nth-child({j+1}) > div.review_cont > div.poll_sample > dl:nth-child(1) > dd > span').text\n",
    "        except:\n",
    "            skin_type = \"없음\"\n",
    "            \n",
    "        #피부 고민\n",
    "        try:\n",
    "            skin_trouble = driver.find_element(By.CSS_SELECTOR, f'#gdasList > li:nth-child({j+1}) > div.review_cont > div.poll_sample > dl:nth-child(2) > dd > span').text\n",
    "        except:\n",
    "            skin_trouble = \"없음\"\n",
    "            \n",
    "        #자극도\n",
    "        try:\n",
    "            skin_irritation = driver.find_element(By.CSS_SELECTOR, f'#gdasList > li:nth-child({j+1}) > div.review_cont > div.poll_sample > dl:nth-child(3) > dd > span').text\n",
    "        except:\n",
    "            skin_irritation = \"없음\"\n",
    "            \n",
    "            \n",
    "        #엑셀 데이터 쌓기\n",
    "        ws.append([brand,p_name,p_category,price,discount,_id, _star, _info, skin_type, skin_trouble, skin_irritation])\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d4d340",
   "metadata": {},
   "source": [
    "### 웹페이지 해당 주소로 이동하여 크롤링함수를 실행하는 반복문을 만듭니다.\n",
    "반복문에 들어가야 하는 것  \n",
    "1. 리뷰버튼 클릭  \n",
    "2. 화면 맨 아래까지 스크롤하기 (코드제공)\n",
    "3. 10페이지 이하일 때 : 10페이지 크롤링 한 후 다음페이지 화살표 버튼 누르기 , 마지막 페이지인 경우 last_page==True\n",
    "4. 11페이지부터 규칙을찾아 다음페이지로 이동하게 만들기, 마지막 페이지인 경우 last_page==True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "abfb0e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#웹페이지 해당 주소 이동\n",
    "for i in range(8,9):          #전체 제품을 한번에 크롤링하지 않고 나눠서 크롤링 할 경우 sub_url 인덱스 고려해서 range숫자 변경\n",
    "\n",
    "\n",
    "    driver.implicitly_wait(5)  #웹페이지 로딩 될때까지 5초는 기다림\n",
    "    driver.maximize_window()   #화면 최대화\n",
    "    driver.get(sub_url[i])          \n",
    "    time.sleep(3)\n",
    "\n",
    "\n",
    "    #리뷰버튼 클릭\n",
    "    rv = driver.find_element(By.CSS_SELECTOR, 'a.goods_reputation')\n",
    "    rv.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "\n",
    "    #리뷰 하단 끝까지 스크롤하는 함수 (빈칸없음.그대로 코드 사용가능)\n",
    "    before_h = driver.execute_script(\"return window.scrollY\")         #스크롤 전 높이\n",
    "    \n",
    "    #화면 맨아래까지 스크롤\n",
    "    while True:\n",
    "        driver.find_element(By.CSS_SELECTOR,\"body\").send_keys(Keys.END)\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "        #스크롤 후 높이\n",
    "        after_h = driver.execute_script(\"return window.scrollY\")\n",
    "\n",
    "        #스크롤 값이 같으면 스크롤 멈춤\n",
    "        if after_h == before_h:\n",
    "            break\n",
    "        before_h = after_h   \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    last_page=False\n",
    "    \n",
    "    for k in range(1,101):  #100페이지 크롤링 한다고 했을 때 (상품당 최대 100페이지까지 있음)\n",
    "\n",
    "        #마지막 페이지면 종료\n",
    "        if last_page == True:\n",
    "            break\n",
    "\n",
    "        #페이지 숫자 10이하 일 때\n",
    "        if k<11:\n",
    "            \n",
    "            try:    \n",
    "                if k != 10:\n",
    "                    customer_info()\n",
    "                    tag = 'div.pageing > ' + 'a:nth-child(' + str(k+1) + ')'\n",
    "                    nt = driver.find_element(By.CSS_SELECTOR, tag)\n",
    "                    nt.click()\n",
    "\n",
    "                elif k == 10:          #10페이지 크롤링 한 후에 다음페이지로 가는 화살표 버튼 클릭\n",
    "                    customer_info()\n",
    "                    nt = driver.find_element(By.CSS_SELECTOR, 'a.next')\n",
    "                    nt.click()\n",
    "                    \n",
    "            except:\n",
    "                   break\n",
    "                    \n",
    "\n",
    "       #페이지 숫자 11이상 일 때  (규칙을 찾아 각 페이지 크롤링 후 다음 페이지로 이동하도록 코드 작성)        \n",
    "        elif k>10 :\n",
    "\n",
    "            try:\n",
    "                if k % 10 != 0:\n",
    "                    customer_info()\n",
    "                    tag = 'div.pageing > ' + 'a:nth-child(' + str(k%10+2) + ')'  # k가 11 이상일 때부터 html이 조금 달라짐\n",
    "                    nt = driver.find_element(By.CSS_SELECTOR, tag)\n",
    "                    nt.click()\n",
    "                elif k % 10 == 0:  \n",
    "                    customer_info()\n",
    "                    nt = driver.find_element(By.CSS_SELECTOR, 'a.next')\n",
    "                    nt.click()\n",
    "\n",
    "            except:\n",
    "                   break\n",
    "                    \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362fa376",
   "metadata": {},
   "source": [
    "### 크롤링한 결과를 엑셀에 저장 (상단에서 만든 엑셀 파일명고 동일하게)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f2d616c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.save(\"크롤링_상품_추가1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0d2ec225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# 저장된 엑셀 파일 경로\n",
    "excel_file_path = \"크롤링_상품_추가1.xlsx\"\n",
    "\n",
    "# 엑셀 파일 열기\n",
    "if os.path.exists(excel_file_path):\n",
    "    subprocess.run([\"start\", excel_file_path], shell=True)\n",
    "else:\n",
    "    print(f\"{excel_file_path} 파일을 찾을 수 없습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
